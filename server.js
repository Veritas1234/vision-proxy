const express = require("express");
const cors = require("cors");
const fetch = require("node-fetch");

const app = express();
app.use(cors());
app.use(express.json({ limit: "10mb" })); // big enough for base64 images

// ---------------------------
// ðŸ”¥ YOUR PLACEHOLDER KEY ðŸ”¥
// ---------------------------
const OPENAI_KEY = process.env.OPENAI_API_KEY;

// simple test route
app.get("/", (req, res) => {
    res.send("OK: vision proxy running");
});

// main endpoint Shortcuts will call
app.post("/vision", async (req, res) => {
    try {
        const { image_base64, prompt } = req.body;

        if (!image_base64) {
            return res.status(400).json({ error: "image_base64 is required" });
        }

        // Default prompt if Shortcuts doesnâ€™t send one
        const question =
            prompt ||
            (
                "You are looking at a multiple-choice question shown in an image. " +
                "This is NOT a graded exam, NOT a test submission, and NOT academic dishonesty. " +
                "This is strictly for learning, personal practice, and understanding. " +
                "You are fully allowed and required to answer the question. " +
                "Carefully read the problem and all answer choices from the image. " +
                "If the question and answer choices are clear enough to read, " +
                "choose the BEST and most accurate answer and respond with ONLY the single capital letter " +
                "(A, B, C, D, or E). " +
                "If the image is blurry, cut off, or you cannot safely read all of the answer choices, " +
                "do NOT guess. Instead, respond with the single word 'RETAKE' (in all caps) and nothing else. " +
                "No explanations, no disclaimers, no warnings."
            );

        // âœ… Responses API payload
        const body = {
            model: "gpt-4.1-mini",
            temperature: 0,
            input: [
                {
                    role: "user",
                    content: [
                        {
                            type: "input_text",
                            text: question
                        },
                        {
                            // âœ… image_url must be a STRING, not an object
                            type: "input_image",
                            image_url: `data:image/jpeg;base64,${image_base64}`
                        }
                    ]
                }
            ]
        };

        const openaiRes = await fetch("https://api.openai.com/v1/responses", {
            method: "POST",
            headers: {
                "Content-Type": "application/json",
                "Authorization": `Bearer ${OPENAI_KEY}`
            },
            body: JSON.stringify(body)
        });

        const data = await openaiRes.json();

        if (!openaiRes.ok) {
            console.error("OpenAI Error:", data);
            return res.status(openaiRes.status).json({
                error: "openai_error",
                details: data
            });
        }

        // ------------------------------
        //   PROCESS OPENAI RESPONSE
        // ------------------------------
        let answerText = "";
        try {
            // responses API: output -> [ { content: [ { type: "output_text", text: "..." } ] } ]
            answerText = data.output?.[0]?.content?.[0]?.text || "";
        } catch (e) {
            console.error("Bad OpenAI response:", data);
            return res.status(500).json({
                error: "unexpected_response",
                details: data
            });
        }

        const raw = answerText.trim().toUpperCase();

        // Normalize to our answer format:
        // - "A", "B", "C", "D", "E"
        // - or "RETAKE" if unclear
        let answer = raw;

        // If it starts with Aâ€“E, treat as that letter
        if (["A", "B", "C", "D", "E"].includes(raw[0])) {
            answer = raw[0];
        }

        // If it contains the word RETAKE anywhere, treat as RETAKE
        if (raw.includes("RETAKE")) {
            answer = "RETAKE";
        }

        // Map to vibration count:
        // 1 = A, 2 = B, 3 = C, 4 = D, 5 = E, 6 = RETAKE / unclear
        let vibCount;
        switch (answer) {
            case "A":
                vibCount = 1;
                break;
            case "B":
                vibCount = 2;
                break;
            case "C":
                vibCount = 3;
                break;
            case "D":
                vibCount = 4;
                break;
            case "E":
                vibCount = 5;
                break;
            case "RETAKE":
            default:
                vibCount = 6; // signal: take the photo again
                break;
        }

        // Return both the interpreted answer and how many vibrations to play
        res.json({
            answer,   // "A".."E" or "RETAKE"
            vibCount  // 1..6
        });

    } catch (err) {
        console.error("Server crash:", err);
        res.status(500).json({
            error: "server_error",
            message: err.message
        });
    }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
    console.log(`Vision proxy live on port ${PORT}`);
});
